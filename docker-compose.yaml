version: "3.8"

# ──────────────────────────── Persistent volumes ──────────────────────────
volumes:
  redis-data:
  weaviate-data:

# ──────────────────────────────── Services ────────────────────────────────
services:

# ── Key / value store ─────────────────────────────────────────────────────
  redis:
    image: redis:7-alpine
    command: ["redis-server", "--save", "60", "1", "--loglevel", "warning"]
    volumes:
      - redis-data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep PONG"]
      interval: 10s
      timeout: 5s
      retries: 3
    ports:
      - "6379:6379"            # expose to host as well

# ── Vector DB (Weaviate) ──────────────────────────────────────────────────
  weaviate:
    image: semitechnologies/weaviate:1.24.8
    environment:
      QUERY_DEFAULTS_LIMIT:                          25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED:      "true"
      PERSISTENCE_DATA_PATH:                        "/var/lib/weaviate"
      DEFAULT_VECTORIZER_MODULE:                    "none"     # we supply embeddings
      ENABLE_MODULES:                               ""         # no server-side vectors
    volumes:
      - weaviate-data:/var/lib/weaviate
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-qO", "-", "http://localhost:8080/v1/.well-known/ready"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 10s
    ports:
      - "8080:8080"

# ── FastAPI RAG / Agent stack ─────────────────────────────────────────────
  agent-server:
    build: .
    command: >
      uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    volumes:
      - ./:/app
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      weaviate:
        condition: service_healthy
    ports:
      - "8000:8000"

    environment:
      # — LangSmith / tracing (unchanged) —
      LANGCHAIN_TRACING_V2: "true"
      LANGCHAIN_API_KEY:   "${LANGCHAIN_API_KEY}"
      LANGCHAIN_PROJECT:   "${LANGCHAIN_PROJECT:-rag-stack}"

      # LLM + embeddings
      LLM_BACKEND:           "${LLM_BACKEND}"              # openai  / bedrock / …
      OPENAI_API_BASE:       "${OPENAI_API_BASE}"
      OPENAI_API_KEY:        "${OPENAI_API_KEY}"
      OPENAI_MODEL:          "${OPENAI_MODEL}"
      EMBEDDING_BACKEND:     "${EMBEDDING_BACKEND:-hf}"    # hf / openai / local
      HF_EMBED_MODEL:        "${HF_EMBED_MODEL}"
      OPENAI_EMBED_MODEL:    "${OPENAI_EMBED_MODEL:-text-embedding-3-small}"
      HUGGINGFACE_HUB_TOKEN: "${HUGGINGFACE_HUB_TOKEN}"

      # ===== Bedrock =====
      AWS_ACCESS_KEY_ID:     "${AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
      AWS_REGION:            "${AWS_REGION:-us-east-1}"
      BEDROCK_REGION:        "${BEDROCK_REGION:-us-east-1}"
      BEDROCK_MODEL_ID:      "${BEDROCK_MODEL_ID}"
      BEDROCK_EMBED_MODEL:   "${BEDROCK_EMBED_MODEL}"

      # — In-cluster addresses —
      REDIS_HOST:    "redis"
      WEAVIATE_URL:  "http://weaviate:8080"

      # — Auth for API & UI —
      ADMIN_TOKEN:   "${ADMIN_TOKEN}"
      USER_TOKEN:    "${USER_TOKEN}"

# ── Streamlit UI ──────────────────────────────────────────────────────────
  ui:
    build: ./ui
    volumes:
      - ./ui:/app
    environment:
      BACKEND_URL:  "http://agent-server:8000"
      AUTH_TOKEN:   "${ADMIN_TOKEN:-supersecrettoken}"
      STREAMLIT_SERVER_RUN_ON_SAVE: "true"
    depends_on:
      agent-server:
        condition: service_started
    ports:
      - "8501:8501"
